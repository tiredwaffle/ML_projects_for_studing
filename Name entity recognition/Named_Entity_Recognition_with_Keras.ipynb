{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Named_Entity_Recognition_with_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLK7Y1jiNXDa",
        "outputId": "8ab3256a-a2aa-4b7a-92da-0e765066301c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import tensorflow as tf\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4N_AW6lMbB5N"
      },
      "source": [
        "### NER Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsczyGDODoaT",
        "colab_type": "text"
      },
      "source": [
        "Dataset from Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mCKmz4SAbI_m",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('ner_dataset.csv', encoding='latin1')\n",
        "data = data.fillna(method = 'ffill')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk9nIy55FV-Q",
        "colab_type": "code",
        "outputId": "c88e9695-765e-4d7d-fffd-7fe6b3cdac14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "data.head(24)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>war</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demand</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>British</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>troops</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>from</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>that</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>country</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1   Sentence: 1             of   IN      O\n",
              "2   Sentence: 1  demonstrators  NNS      O\n",
              "3   Sentence: 1           have  VBP      O\n",
              "4   Sentence: 1        marched  VBN      O\n",
              "5   Sentence: 1        through   IN      O\n",
              "6   Sentence: 1         London  NNP  B-geo\n",
              "7   Sentence: 1             to   TO      O\n",
              "8   Sentence: 1        protest   VB      O\n",
              "9   Sentence: 1            the   DT      O\n",
              "10  Sentence: 1            war   NN      O\n",
              "11  Sentence: 1             in   IN      O\n",
              "12  Sentence: 1           Iraq  NNP  B-geo\n",
              "13  Sentence: 1            and   CC      O\n",
              "14  Sentence: 1         demand   VB      O\n",
              "15  Sentence: 1            the   DT      O\n",
              "16  Sentence: 1     withdrawal   NN      O\n",
              "17  Sentence: 1             of   IN      O\n",
              "18  Sentence: 1        British   JJ  B-gpe\n",
              "19  Sentence: 1         troops  NNS      O\n",
              "20  Sentence: 1           from   IN      O\n",
              "21  Sentence: 1           that   DT      O\n",
              "22  Sentence: 1        country   NN      O\n",
              "23  Sentence: 1              .    .      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLw32qGVFTe3",
        "colab_type": "text"
      },
      "source": [
        "Soo what we see is a sentence of 24 words with every words POS tagged and marked as the Name Entity (and which type exactly) or not. \n",
        "\n",
        "The dataset has 47959 sentences. \n",
        "\n",
        "*Info about tagged entities*:\n",
        "- geo = Geographical Entity\n",
        "- org = Organization\n",
        "- per = Person\n",
        "- gpe = Geopolitical Entity\n",
        "- tim = Time indicator\n",
        "- art = Artifact\n",
        "- eve = Event\n",
        "- nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "riOztP-8NXHT",
        "outputId": "592aeba9-7b00-427a-979e-02b44831de9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print('Unique words in out corpus:', data['Word'].nunique())\n",
        "print('Unique tags in out corpus:', data['Tag'].nunique())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in out corpus: 23008\n",
            "Unique tags in out corpus: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxWwlqcmDobW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(data['Word'].values))\n",
        "words.append('ENDPAD')\n",
        "num_words = len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgJKYc39Dobx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = list(set(data['Tag'].values))\n",
        "num_tags = len(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-RAKITdHsuG",
        "colab_type": "code",
        "outputId": "45397feb-8389-48a4-faaa-d7ba34a04f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "num_words, num_tags"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23009, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M9D9JEzUbdnS"
      },
      "source": [
        "### Sentences and Corresponsing Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdJst_g5NYY_",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "  def __init__(self, data):\n",
        "    self.n_sent = 1\n",
        "    self.data = data\n",
        "    agg_func = lambda s: [(w, p, t) for w,p,t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                     s[\"POS\"].values.tolist(),\n",
        "                                                     s[\"Tag\"].values.tolist())]\n",
        "    self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
        "    self.sentences = [s for s in self.grouped]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nMUQLppspkPj",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GhiSTt2UdzYC",
        "outputId": "4e46c06b-8138-4b75-cbce-b43d711800c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'NNS', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('demonstrators', 'NNS', 'O'),\n",
              " ('have', 'VBP', 'O'),\n",
              " ('marched', 'VBN', 'O'),\n",
              " ('through', 'IN', 'O'),\n",
              " ('London', 'NNP', 'B-geo'),\n",
              " ('to', 'TO', 'O'),\n",
              " ('protest', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('war', 'NN', 'O'),\n",
              " ('in', 'IN', 'O'),\n",
              " ('Iraq', 'NNP', 'B-geo'),\n",
              " ('and', 'CC', 'O'),\n",
              " ('demand', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('withdrawal', 'NN', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('British', 'JJ', 'B-gpe'),\n",
              " ('troops', 'NNS', 'O'),\n",
              " ('from', 'IN', 'O'),\n",
              " ('that', 'DT', 'O'),\n",
              " ('country', 'NN', 'O'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCSWxhc3Kd81",
        "colab_type": "text"
      },
      "source": [
        "So we splitted the data into separate objects (1 sentence = 1 object)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SvENHO18pkaQ",
        "colab": {}
      },
      "source": [
        "words2idx = {w: i+1 for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i,t in enumerate(tags)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-r4PR85hpoF"
      },
      "source": [
        "### Bidirectional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R44g5T7NYp_H",
        "outputId": "3fb7f0aa-25a5-45bf-b883-0ab5086fc211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(s) for s in sentences], bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FS4u3CRkpkc1",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "X = [[words2idx[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen = max_len, sequences = X, padding = 'post', value = num_words-1)\n",
        "\n",
        "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen = max_len, sequences = y, padding = 'post', value = tag2idx['O'])\n",
        "y = [to_categorical(i, num_classes = num_tags) for i in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7VfnnkXpkfS",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2vM7IkXpkiH",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKeUf_6OVO2y",
        "colab_type": "text"
      },
      "source": [
        "**SpatialDropout1D**\n",
        "\n",
        "Example is this: shape(x) = [k, l, m, n] and noise_shape = [k, 1, 1, n]. In this case, each batch and channel component will be kept independently, but each row and column will be kept or not kept together. In other words, the whole [l, m] feature map will be either kept or dropped.\n",
        "\n",
        "You may want to do this to account for adjacent pixels correlation, especially in the early convolutional layers. Effectively, you want to prevent co-adaptation of pixels with its neighbors across the feature maps, and make them learn as if no other feature maps exist. This is exactly what SpatialDropout2D is doing: it promotes independence between feature maps.\n",
        "\n",
        "The SpatialDropout1D is very similar: given shape(x) = [k, l, m] it uses noise_shape = [k, 1, m] and drops entire 1-D feature maps.\n",
        "___\n",
        "**Bidirectional LSTMs**\n",
        "\n",
        "Bidirectional LSTMs are an extension of traditional LSTMs that can improve model performance on sequence classification problems.\n",
        "\n",
        "In problems where all timesteps of the input sequence are available, Bidirectional LSTMs train two instead of one LSTMs on the input sequence. The first on the input sequence as-is and the second on a reversed copy of the input sequence. This can provide additional context to the network and result in faster and even fuller learning on the problem.\n",
        "___\n",
        "**TimeDistributedDense**\n",
        "\n",
        "TimeDistributedDense applies a same Dense (fully-connected) operation to every timestep of a 3D tensor. This wrapper allows us to apply a layer to every temporal slice of an input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aee3mCZ3pkkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "13ca5040-3e34-493b-ae65-4bdaf9a8d57d"
      },
      "source": [
        "input_word = Input(shape = (max_len,))\n",
        "model = Embedding(input_dim = num_words, output_dim = max_len, input_length = max_len)(input_word)\n",
        "model = SpatialDropout1D(0.1)(model)\n",
        "model = Bidirectional(LSTM(units = 100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(num_tags, activation = 'softmax'))(model)\n",
        "model = Model(input_word, out)\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 50, 50)            1150450   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 50, 200)           120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 50, 17)            3417      \n",
            "=================================================================\n",
            "Total params: 1,274,667\n",
            "Trainable params: 1,274,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOBpQg26pkqh",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5ThSjN5DogS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from livelossplot.tf_keras import PlotLossesCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9HWH06Ypkxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "82f24507-a356-4d45-c09d-248ca4edf8cb"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 2, mode = 'max')\n",
        "callbacks = [ early_stopping]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, np.array(y_train),\n",
        "    validation_split = 0.2,\n",
        "    batch_size = 64,\n",
        "    epochs = 10,\n",
        "    verbose = 1,\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "224/224 [==============================] - 98s 439ms/step - loss: 0.4237 - accuracy: 0.9300 - val_loss: 0.2072 - val_accuracy: 0.9398\n",
            "Epoch 2/50\n",
            "224/224 [==============================] - 98s 439ms/step - loss: 0.1623 - accuracy: 0.9497 - val_loss: 0.1428 - val_accuracy: 0.9550\n",
            "Epoch 3/50\n",
            "224/224 [==============================] - 98s 439ms/step - loss: 0.1072 - accuracy: 0.9690 - val_loss: 0.0952 - val_accuracy: 0.9750\n",
            "Epoch 4/50\n",
            "224/224 [==============================] - 98s 436ms/step - loss: 0.0677 - accuracy: 0.9813 - val_loss: 0.0745 - val_accuracy: 0.9794\n",
            "Epoch 5/50\n",
            "224/224 [==============================] - 97s 433ms/step - loss: 0.0502 - accuracy: 0.9858 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
            "Epoch 6/50\n",
            "224/224 [==============================] - 97s 435ms/step - loss: 0.0408 - accuracy: 0.9883 - val_loss: 0.0656 - val_accuracy: 0.9817\n",
            "Epoch 7/50\n",
            "224/224 [==============================] - 99s 441ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.0662 - val_accuracy: 0.9816\n",
            "Epoch 8/50\n",
            "224/224 [==============================] - 99s 442ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0707 - val_accuracy: 0.9817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2nwnnF0ziU3B"
      },
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6euqX7UHplG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2117b911-125f-43c7-8bfa-3a16849d1527"
      },
      "source": [
        "model.evaluate(X_test, np.array(y_test))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 2s 37ms/step - loss: 0.0756 - accuracy: 0.9808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0756278857588768, 0.9808366894721985]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tyg4mKOVplJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "fec78e26-e5c4-4edb-9292-e3c5447671a9"
      },
      "source": [
        "i = np.random.randint(0, X_test.shape[0])\n",
        "p = model.predict(np.array([X_test[i]]))\n",
        "p = np.argmax(p, axis=-1)\n",
        "\n",
        "y_true = np.argmax(np.array(y_test), axis = -1)[i]\n",
        "print(\"{:15} {} \\t{} \".format('Words', 'Tags', 'Pred'))\n",
        "print('-'*30)\n",
        "for w, true, pred in zip(X_test[i], y_true, p[0]):\n",
        "  print('{:15}{}\\t{}'.format(words[w-1], tags[true], tags[pred]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words           Tags \tPred \n",
            "------------------------------\n",
            "The            O\tO\n",
            "agreement      O\tO\n",
            "comes          O\tO\n",
            "one            O\tO\n",
            "week           O\tO\n",
            "after          O\tO\n",
            "Japan          B-geo\tB-geo\n",
            "adopted        O\tO\n",
            "new            O\tO\n",
            "defense        O\tO\n",
            "policy         O\tO\n",
            "guidelines     O\tO\n",
            "that           O\tO\n",
            "would          O\tO\n",
            "allow          O\tO\n",
            "the            O\tO\n",
            "joint          O\tO\n",
            "development    O\tO\n",
            "of             O\tO\n",
            "a              O\tO\n",
            "missile        O\tO\n",
            "defense        O\tO\n",
            "system         O\tO\n",
            "with           O\tO\n",
            "the            O\tO\n",
            "United         B-geo\tB-geo\n",
            "States         I-geo\tI-geo\n",
            ".              O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n",
            "despoiling     O\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PJBZ6wGm-TS",
        "colab_type": "text"
      },
      "source": [
        "Looks good. \n",
        "\n",
        "With test accuracy of 0.9808 for max(10) epoches this looks like a valid way for looking for name entities."
      ]
    }
  ]
}